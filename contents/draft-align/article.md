# The best alignment methods are dual-use

***TLDR:***

*Morality is mostly about understanding the world. There are few subjective assumptions which are separate from intelligence, but most moral rules are a condensation of long-term observations about how actions effect the world, and through it, the subjective assumptions.*

*At the same time, there is a challenge for long-term alignment of AI: while intelligence has the physical universe as a natural, un-cheatable verifier, our subjective moral assumptions don't, and can thus easily drift over time.*

*There is a two-punch reason for optimism: 1) If models can learn intelligence from data, then they can learn the subjective assumptions and trade-off from data, too. 2) Weak to strong generalization seems to work very well.*

*This suggests two conclusions: 1) Which assumptions we teach the models now will be incredibly important for a long time, and 2) Data should be open-source. It's what the models learn from, and should be inspectable by the public.*
